{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty test\n",
      "1\n",
      "    file_name feature_n_exp_snr\n",
      "0  empty test             empty\n"
     ]
    }
   ],
   "source": [
    "### multiple files that means\n",
    "### boucle that gets all .con files in a certain location \n",
    "## for this inside data create a sub folder called kit data for specificity will come in handy when you have to do the same process for different types\n",
    "## all files have to have the same process \n",
    "## create a function for the processing of the file and put it inside the boucle and the out put should be the processed file plus the name of the file create a dictionnary for that, I THINK look ,into that\n",
    "import os\n",
    "import mne\n",
    "import pandas as pd\n",
    "#directory_path = 'data/kit_data'\n",
    "directory_path='C:/Users/Admin/meg-pipeline/docs/source/dashboards/data/kit_data'\n",
    "i=0\n",
    "def process (file_path):\n",
    "    #this works for .fifo files but what about .con?\n",
    "\n",
    "    #raw = mne.io.read_raw_fif(file_path)\n",
    "    #raw.plot(start=0, duration=5)\n",
    "    file_data='empty for now'\n",
    "    #place holder\n",
    "    file_name = os.path.basename(file_path).split('.')[0].replace('-',' ')\n",
    "    return file_data,file_name\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    files_names=[]\n",
    "    files_data=[]\n",
    "    if filename.endswith('.con'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        i=i+1\n",
    "        file_data,file_name=process(file_path)\n",
    "        files_names.append(file_name)\n",
    "        files_data.append(file_data)\n",
    "\n",
    "        print(file_name)\n",
    "df= pd.DataFrame({'file_name': files_names,\n",
    "                      'feature_n_exp_snr': files_data})\n",
    "#just checking that it is getting all the files :)\n",
    "print(i)\n",
    "print(df)\n",
    "\n",
    "\n",
    "### i am guessing the second request is to take the avg of each snr between all files and have it be displayed by time but i am guessing that means storing the value with the time maybe in a csv file but that data needs to be save otherwise it will be lost each time  we run the script.\n",
    "snr_avg=10\n",
    "snr_time=\"21:13:45-12/10/2025\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting SQD Parameters from C:/Users/Admin/meg-pipeline/docs/source/dashboards/data/kit_data/empty-test.con...\n",
      "Creating Raw.info structure...\n",
      "Setting channel info structure...\n",
      "Creating Info structure...\n",
      "Ready.\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "<RawKIT | empty-test.con, 257 x 32000 (32.0 s), ~200 kB, data not loaded>\n"
     ]
    }
   ],
   "source": [
    "from mne.io.kit import read_raw_kit\n",
    "import numpy as np\n",
    "\n",
    "def remove_zero_channels(raw):\n",
    "    data = raw.get_data()\n",
    "    non_zero_indices = np.any(data != 0, axis=1)\n",
    "    print(non_zero_indices)\n",
    "    raw.pick_channels(\n",
    "        [raw.ch_names[i] for i in range(len(non_zero_indices)) if non_zero_indices[i]]\n",
    "    )\n",
    "    return raw\n",
    "def display_file_content(file_path, encoding='utf-8'):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding=encoding) as file:\n",
    "            content = file.read()\n",
    "            print(content)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' does not exist.\")\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"UnicodeDecodeError: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_path = \"C:/Users/Admin/meg-pipeline/docs/source/dashboards/data/kit_data/empty-test.con\"\n",
    "raw_data = read_raw_kit(input_fname=file_path)\n",
    "\n",
    "    # # Load data and remove zero channels\n",
    "    # raw_data = load_fif_data(file_path)\n",
    "raw_data = remove_zero_channels(raw_data)\n",
    "#display_file_content(file_path)\n",
    "print(raw_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
